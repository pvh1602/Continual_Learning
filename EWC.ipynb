{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EWC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KMXjaf4pZJN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bc78df8-65f5-414a-fcbd-f09dc5a71475"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tcBzXG-qVQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.utils import shuffle\n",
        "from copy import deepcopy\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qexadtYpSUtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(datapath : str):\n",
        "  \n",
        "  pass\n",
        "  return data, tasknum, ncla\n",
        "\n",
        "def train_epoch():\n",
        "  pass\n",
        "\n",
        "def train_model():\n",
        "  pass\n",
        "\n",
        "def eval_model():\n",
        "  pass\n",
        "\n",
        "def cal_FIM(old_models, cur_model)->float:\n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB9IWRDCnhUy",
        "colab_type": "text"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FEY0BVOUCLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, inputsize, taskcla, hiddensize=400, split=False):\n",
        "        \"\"\"\n",
        "        inputsize : [n_channels, height, width]\n",
        "        taskcla : [(taskid, n_cla),...]\n",
        "        split : True if using split experiments\n",
        "        hiddensize : the number of unit in hidden layers\n",
        "        \"\"\"\n",
        "        super(Network, self).__init__()\n",
        "        ncha, size, _ = inputsize\n",
        "        self.taskcla = taskcla\n",
        "        self.split = split\n",
        "        self.fc1 = nn.Linear(ncha*size*size, hiddensize)\n",
        "        self.fc2 = nn.Linear(hiddensize, hiddensize)\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        if split:\n",
        "            self.last = nn.ModuleList()\n",
        "            for t, n_cla in taskcla:\n",
        "                self.last.append(nn.Linear(hiddensize, n_cla))\n",
        "        else:   # not split experiments\n",
        "            self.last = nn.Linear(hiddensize, taskcla[0][1])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = x.view(x.size(0), -1)   # flatten convert image matrix into vector\n",
        "        h = self.drop(F.relu(self.fc1(h)))\n",
        "        h = self.drop(F.relu(self.fc2(h)))\n",
        "        if self.split:\n",
        "            y = []\n",
        "            for t, _ in self.taskcla:\n",
        "                y.append(self.last[t](h))\n",
        "        else:\n",
        "            y = self.last(h)\n",
        "        return y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI3o5J6XnjW5",
        "colab_type": "text"
      },
      "source": [
        "# Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYbFhz7SUNwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EWC():\n",
        "\n",
        "    def __init__(self, model, nepochs=100, sbatch=256, lr=0.001, lamb=100, split=False):\n",
        "        self.model = model\n",
        "        self.model_old = model\n",
        "        self.fisher = {}\n",
        "        self.params_opt = {}\n",
        "        self.nepochs = nepochs\n",
        "        self.sbatch = sbatch        \n",
        "        self.lr = lr\n",
        "        self.split = split\n",
        "        self.lamb = lamb\n",
        "\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr)\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "        else:\n",
        "            self.device = 'cpu'\n",
        "\n",
        "    def train(self, taskid, xtrain, ytrain, data):\n",
        "\n",
        "        for e in range(self.nepochs):\n",
        "            clock0 = time.time()\n",
        "            self.train_epoch(taskid, xtrain, ytrain)\n",
        "            clock1 = time.time()\n",
        "            train_loss, train_acc = self.eval(taskid, xtrain, ytrain)\n",
        "            clock2 = time.time()\n",
        "            if (e % 5 == 0):\n",
        "                print('| Epoch {:3d}, train_time={:5.1f}ms, eval_time={:5.1f}ms | \\\n",
        "                        Train: loss={:.3f}, acc={:5.1f}% |'.format(e+1,1000*(clock1-clock0),\n",
        "                                                                   1000*(clock2-clock1),train_loss,100*train_acc))\n",
        "        \n",
        "        self.params_opt[taskid] = {}\n",
        "        for name, param in self.model.named_parameters():\n",
        "            self.params_opt[taskid][name] = param.data.clone()\n",
        "        self.fisher[taskid] = self.cal_Fisher(taskid, xtrain, ytrain)\n",
        "\n",
        "        return\n",
        "\n",
        "    def train_epoch(self, taskid, xtrain, ytrain):\n",
        "        self.model.train()\n",
        "        r = np.arange(xtrain.size(0))\n",
        "        np.random.shuffle(r)\n",
        "        r = torch.LongTensor(r).to(self.device)\n",
        "\n",
        "        for i in range(0, len(r), self.sbatch):\n",
        "            if i + self.sbatch <= len(r):\n",
        "                b = r[i:i+self.sbatch]\n",
        "            else:\n",
        "                b = r[i:]\n",
        "            images = xtrain[b]\n",
        "            targets = ytrain[b]\n",
        "\n",
        "            if self.split:\n",
        "                outputs = self.model.forward(images)[t]\n",
        "            else:\n",
        "                outputs = self.model.forward(images)\n",
        "            \n",
        "            loss = self.criterion(taskid, outputs, targets)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return\n",
        "\n",
        "    def eval(self, taskid, x, y):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        # total_num = 0\n",
        "        self.model.eval()\n",
        "\n",
        "        r = np.arange(x.size(0))\n",
        "        r = torch.LongTensor(r).to(self.device)\n",
        "        for i in range(0, len(r), self.sbatch):\n",
        "            if i + self.sbatch <= len(r):\n",
        "                b = r[i:i+self.sbatch]\n",
        "            else:\n",
        "                b = r[i:]\n",
        "            images = x[b]\n",
        "            targets = y[b]\n",
        "\n",
        "            if self.split:\n",
        "                outputs = self.model.forward(images)[taskid]\n",
        "            else:\n",
        "                outputs = self.model.forward(images)\n",
        "            \n",
        "            _, pred = outputs.max(1)    # pred is index of max value \n",
        "            hits = (pred==targets).float()\n",
        "            loss = self.criterion(taskid, outputs, targets)\n",
        "            \n",
        "            total_loss += loss.data.cpu().numpy()*len(b)\n",
        "            total_acc += hits.sum().data.cpu().numpy()\n",
        "            # total_num += len(b)\n",
        "        \n",
        "        return total_loss/len(r), total_acc/len(r)\n",
        "\n",
        "\n",
        "    def criterion(self, taskid, outputs, targets):\n",
        "        loss_reg = 0\n",
        "        if taskid == 0:\n",
        "            return self.ce(outputs, targets)\n",
        "        for t in range(taskid):\n",
        "            for name, param in self.model.named_parameters():\n",
        "                fisher = self.fisher[t][name]\n",
        "                opt_param = self.params_opt[t][name]\n",
        "                loss_reg += torch.sum(fisher*(param.data - opt_param).pow(2))/2\n",
        "        return self.ce(outputs, targets) + self.lamb*loss_reg\n",
        "    \n",
        "    def cal_Fisher(self, taskid, xtrain, ytrain):\n",
        "        \"\"\"\n",
        "        return fisher[name_param]\n",
        "        \"\"\"\n",
        "        print(\"Calculating Fisher Information Matrix ...\")\n",
        "        fisher = {}\n",
        "        for name, param in self.model.named_parameters():\n",
        "            fisher[name] = 0*param.data\n",
        "        #Note only with model.train() we can compute grad\n",
        "        self.model.train()\n",
        "\n",
        "        r = np.arange(xtrain.size(0))\n",
        "        np.random.shuffle(r)\n",
        "        r = torch.LongTensor(r).to(self.device)\n",
        "\n",
        "        for i in range(0, len(r), self.sbatch):\n",
        "            if i + self.sbatch <= len(r):\n",
        "                b = r[i:i+self.sbatch]\n",
        "            else:\n",
        "                b = r[i:]\n",
        "            images = xtrain[b]\n",
        "            targets = ytrain[b]\n",
        "\n",
        "            self.model.zero_grad()\n",
        "            if self.split:\n",
        "                outputs = self.model.forward(images)[taskid]\n",
        "            else:\n",
        "                outputs = self.model.forward(images)\n",
        "            \n",
        "            loss = self.criterion(taskid, outputs, targets)\n",
        "            loss.backward()\n",
        "\n",
        "            # Get fisher through gradient of param\n",
        "            for name, param in self.model.named_parameters():\n",
        "                if param.grad is not None:\n",
        "                    # Instead of Calculating Hessian, FIM approximates it\n",
        "                    # by computing first order derivations                                        \n",
        "                    fisher[name] += param.grad.data.pow(2)*self.sbatch  \n",
        "            \n",
        "        # average fisher over all data in this task\n",
        "        with torch.no_grad():\n",
        "            for name, param in self.model.named_parameters():     \n",
        "                fisher[name] /= xtrain.size(0)\n",
        "        print(\"Calculated Fisher Information Matrix.\")\n",
        "        return fisher\n",
        "\n",
        "\n",
        "            \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F_vUr_7nl8l",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szVxo_nHqavp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(datapath, tasknum=10, seed=0):\n",
        "    np.random.seed(seed)\n",
        "    data = {}\n",
        "    taskcla = []\n",
        "    size = [1, 28, 28]\n",
        "    mean = torch.Tensor([0.1307]).cpu()\n",
        "    std = torch.Tensor([0.3081]).cpu()\n",
        "    dat = {}\n",
        "    dat['train'] = datasets.MNIST(datapath, train=True, download=True)\n",
        "    dat['test'] = datasets.MNIST(datapath, train=False, download=True)\n",
        "\n",
        "    for i in range(tasknum):\n",
        "        sys.stdout.flush()\n",
        "        data[i] = {}\n",
        "        data[i]['name'] = 'pmnist-{:d}'.format(i)\n",
        "        data[i]['ncla'] = 10\n",
        "        permutation = np.random.permutation(28*28)\n",
        "        for s in ['train', 'test']:\n",
        "            if s == 'train':\n",
        "                arr = dat[s].train_data.view(dat[s].train_data.shape[0], -1).float()\n",
        "                label = torch.LongTensor(dat[s].train_labels)\n",
        "            else:\n",
        "                arr = dat[s].test_data.view(dat[s].test_data.shape[0], -1).float()\n",
        "                label = torch.LongTensor(dat[s].test_labels)\n",
        "            \n",
        "            # print(arr[0])\n",
        "            # print(mean)\n",
        "\n",
        "            arr = (arr/255 - mean)/std\n",
        "\n",
        "            data[i][s] = {}\n",
        "            data[i][s]['x'] = arr[:, permutation].view(-1, size[0], size[1], size[2])\n",
        "            data[i][s]['y'] = label\n",
        "\n",
        "    n = 0\n",
        "    for t in range(tasknum):\n",
        "        taskcla.append((t, data[t]['ncla']))\n",
        "        n += data[t]['ncla']\n",
        "    data['ncla'] = n\n",
        "\n",
        "    return data, taskcla, size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkVtpoi4noq6",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTES6HUTOPe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    datapath = '../../dat/'\n",
        "    print(\"Loading data...\")\n",
        "    data, taskcla, inputsize = get_data(datapath, tasknum=10)\n",
        "    print('Input size =', inputsize, '\\nTask info =', taskcla)\n",
        "    # Inits\n",
        "    print('Inits...')\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    net = Network(inputsize, taskcla, hiddensize=400, split=False)\n",
        "    appr = EWC(net, nepochs=100, sbatch=256, lr=0.001, lamb=400, split=False)\n",
        "    \n",
        "    acc = np.zeros((len(taskcla), len(taskcla)), dtype=np.float32)\n",
        "    loss = np.zeros((len(taskcla), len(taskcla)), dtype=np.float32)\n",
        "    for i in range(len(taskcla)):\n",
        "        print('*' * 100)\n",
        "        print('Task {:2d} ({:s})'.format(i, data[i]['name']))\n",
        "        print('*' * 100)\n",
        "\n",
        "        xtrain = data[i]['train']['x'].to(device)\n",
        "        ytrain = data[i]['train']['y'].to(device)\n",
        "\n",
        "        # xtest = data[i]['test']['x'].to(device)\n",
        "        # ytest = data[i]['test']['y'].to(device)\n",
        "\n",
        "        appr.train(taskid=i, xtrain=xtrain, ytrain=ytrain, data=data)\n",
        "        print('-' * 100)\n",
        "\n",
        "        # Test\n",
        "        for j in range(i+1):\n",
        "            xtest = data[j]['test']['x'].to(device)\n",
        "            ytest = data[j]['test']['y'].to(device)\n",
        "            loss[i,j], acc[i,j] = appr.eval(taskid=j, x=xtest, y=ytest)\n",
        "            print('>>> Test on task {:2d} - {:15s}: loss={:.3f}, acc={:5.1f}% <<<'.format(j, data[j]['name'], loss[i,j],\n",
        "                                                                                      100 * acc[i,j]))\n",
        "    \n",
        "    # Done\n",
        "    print('*' * 100)\n",
        "    print('Accuracies =')\n",
        "    for i in range(acc.shape[0]):\n",
        "        print('\\t', end='')\n",
        "        for j in range(acc.shape[1]):\n",
        "            print('{:5.1f}% '.format(100 * acc[i, j]), end='')\n",
        "        print()\n",
        "    print('*' * 100)\n",
        "    \n",
        "    print()\n",
        "    avg_acc = np.mean(acc[acc.shape[0]-1,:])\n",
        "    print ('ACC: {:5.4f}%'.format(avg_acc))\n",
        "    print()\n",
        "    \n",
        "    ucb_bwt = (acc[-1] - np.diag(acc)).mean()\n",
        "    print ('BWT : {:5.2f}%'.format(ucb_bwt))\n",
        "\n",
        "    print('Done!')\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uwz8UVVpmJc",
        "colab_type": "text"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RejChADBnB_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f99490f1-750c-45a0-eb39-67b529a100b8"
      },
      "source": [
        "acc, loss = main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input size = [1, 28, 28] \n",
            "Task info = [(0, 10), (1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10), (8, 10), (9, 10)]\n",
            "Inits...\n",
            "****************************************************************************************************\n",
            "Task  0 (pmnist-0)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=421.5ms, eval_time=265.0ms |                         Train: loss=2.234, acc= 38.0% |\n",
            "| Epoch   6, train_time=401.4ms, eval_time=222.3ms |                         Train: loss=1.645, acc= 68.7% |\n",
            "| Epoch  11, train_time=399.6ms, eval_time=188.9ms |                         Train: loss=0.896, acc= 80.6% |\n",
            "| Epoch  16, train_time=359.6ms, eval_time=210.8ms |                         Train: loss=0.616, acc= 84.5% |\n",
            "| Epoch  21, train_time=369.5ms, eval_time=173.9ms |                         Train: loss=0.505, acc= 86.3% |\n",
            "| Epoch  26, train_time=367.7ms, eval_time=177.6ms |                         Train: loss=0.446, acc= 87.6% |\n",
            "| Epoch  31, train_time=428.1ms, eval_time=172.4ms |                         Train: loss=0.407, acc= 88.5% |\n",
            "| Epoch  36, train_time=360.8ms, eval_time=188.5ms |                         Train: loss=0.379, acc= 89.2% |\n",
            "| Epoch  41, train_time=355.2ms, eval_time=180.7ms |                         Train: loss=0.358, acc= 89.7% |\n",
            "| Epoch  46, train_time=363.3ms, eval_time=180.5ms |                         Train: loss=0.341, acc= 90.1% |\n",
            "| Epoch  51, train_time=358.9ms, eval_time=182.9ms |                         Train: loss=0.326, acc= 90.5% |\n",
            "| Epoch  56, train_time=379.7ms, eval_time=193.4ms |                         Train: loss=0.314, acc= 90.8% |\n",
            "| Epoch  61, train_time=345.6ms, eval_time=179.8ms |                         Train: loss=0.303, acc= 91.0% |\n",
            "| Epoch  66, train_time=357.2ms, eval_time=171.0ms |                         Train: loss=0.293, acc= 91.3% |\n",
            "| Epoch  71, train_time=385.2ms, eval_time=178.4ms |                         Train: loss=0.284, acc= 91.5% |\n",
            "| Epoch  76, train_time=365.6ms, eval_time=184.3ms |                         Train: loss=0.276, acc= 91.7% |\n",
            "| Epoch  81, train_time=352.3ms, eval_time=187.5ms |                         Train: loss=0.268, acc= 91.9% |\n",
            "| Epoch  86, train_time=460.6ms, eval_time=209.9ms |                         Train: loss=0.261, acc= 92.1% |\n",
            "| Epoch  91, train_time=349.0ms, eval_time=172.1ms |                         Train: loss=0.255, acc= 92.3% |\n",
            "| Epoch  96, train_time=398.7ms, eval_time=181.1ms |                         Train: loss=0.248, acc= 92.5% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.235, acc= 93.0% <<<\n",
            "****************************************************************************************************\n",
            "Task  1 (pmnist-1)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=600.0ms, eval_time=390.2ms |                         Train: loss=1.318, acc= 63.2% |\n",
            "| Epoch   6, train_time=545.1ms, eval_time=392.5ms |                         Train: loss=0.523, acc= 85.4% |\n",
            "| Epoch  11, train_time=557.3ms, eval_time=416.4ms |                         Train: loss=0.413, acc= 88.3% |\n",
            "| Epoch  16, train_time=686.4ms, eval_time=389.3ms |                         Train: loss=0.364, acc= 89.6% |\n",
            "| Epoch  21, train_time=552.0ms, eval_time=412.6ms |                         Train: loss=0.333, acc= 90.4% |\n",
            "| Epoch  26, train_time=712.9ms, eval_time=390.1ms |                         Train: loss=0.312, acc= 91.0% |\n",
            "| Epoch  31, train_time=723.6ms, eval_time=394.4ms |                         Train: loss=0.295, acc= 91.4% |\n",
            "| Epoch  36, train_time=561.5ms, eval_time=385.4ms |                         Train: loss=0.281, acc= 91.9% |\n",
            "| Epoch  41, train_time=553.6ms, eval_time=390.3ms |                         Train: loss=0.270, acc= 92.2% |\n",
            "| Epoch  46, train_time=548.4ms, eval_time=394.7ms |                         Train: loss=0.260, acc= 92.5% |\n",
            "| Epoch  51, train_time=581.7ms, eval_time=384.0ms |                         Train: loss=0.251, acc= 92.8% |\n",
            "| Epoch  56, train_time=604.8ms, eval_time=380.4ms |                         Train: loss=0.244, acc= 93.0% |\n",
            "| Epoch  61, train_time=586.0ms, eval_time=384.2ms |                         Train: loss=0.237, acc= 93.2% |\n",
            "| Epoch  66, train_time=567.1ms, eval_time=476.1ms |                         Train: loss=0.231, acc= 93.4% |\n",
            "| Epoch  71, train_time=578.6ms, eval_time=381.8ms |                         Train: loss=0.225, acc= 93.6% |\n",
            "| Epoch  76, train_time=591.1ms, eval_time=384.9ms |                         Train: loss=0.219, acc= 93.8% |\n",
            "| Epoch  81, train_time=595.2ms, eval_time=412.1ms |                         Train: loss=0.215, acc= 93.9% |\n",
            "| Epoch  86, train_time=597.8ms, eval_time=392.0ms |                         Train: loss=0.210, acc= 94.1% |\n",
            "| Epoch  91, train_time=718.9ms, eval_time=508.5ms |                         Train: loss=0.206, acc= 94.2% |\n",
            "| Epoch  96, train_time=586.7ms, eval_time=445.3ms |                         Train: loss=0.202, acc= 94.3% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.295, acc= 91.3% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.195, acc= 94.6% <<<\n",
            "****************************************************************************************************\n",
            "Task  2 (pmnist-2)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=813.9ms, eval_time=724.4ms |                         Train: loss=1.061, acc= 68.8% |\n",
            "| Epoch   6, train_time=790.6ms, eval_time=560.4ms |                         Train: loss=0.463, acc= 86.8% |\n",
            "| Epoch  11, train_time=742.6ms, eval_time=715.6ms |                         Train: loss=0.379, acc= 89.3% |\n",
            "| Epoch  16, train_time=769.2ms, eval_time=579.8ms |                         Train: loss=0.340, acc= 90.4% |\n",
            "| Epoch  21, train_time=798.8ms, eval_time=571.3ms |                         Train: loss=0.315, acc= 91.2% |\n",
            "| Epoch  26, train_time=723.6ms, eval_time=552.1ms |                         Train: loss=0.297, acc= 91.8% |\n",
            "| Epoch  31, train_time=775.5ms, eval_time=585.4ms |                         Train: loss=0.283, acc= 92.3% |\n",
            "| Epoch  36, train_time=743.9ms, eval_time=547.7ms |                         Train: loss=0.272, acc= 92.7% |\n",
            "| Epoch  41, train_time=883.2ms, eval_time=561.4ms |                         Train: loss=0.262, acc= 93.0% |\n",
            "| Epoch  46, train_time=913.6ms, eval_time=546.2ms |                         Train: loss=0.254, acc= 93.3% |\n",
            "| Epoch  51, train_time=791.7ms, eval_time=553.2ms |                         Train: loss=0.247, acc= 93.6% |\n",
            "| Epoch  56, train_time=755.4ms, eval_time=567.9ms |                         Train: loss=0.240, acc= 93.8% |\n",
            "| Epoch  61, train_time=758.7ms, eval_time=567.9ms |                         Train: loss=0.234, acc= 94.0% |\n",
            "| Epoch  66, train_time=945.6ms, eval_time=591.7ms |                         Train: loss=0.230, acc= 94.3% |\n",
            "| Epoch  71, train_time=751.7ms, eval_time=597.5ms |                         Train: loss=0.225, acc= 94.4% |\n",
            "| Epoch  76, train_time=887.2ms, eval_time=743.5ms |                         Train: loss=0.221, acc= 94.5% |\n",
            "| Epoch  81, train_time=766.9ms, eval_time=538.0ms |                         Train: loss=0.217, acc= 94.7% |\n",
            "| Epoch  86, train_time=786.9ms, eval_time=544.9ms |                         Train: loss=0.214, acc= 94.8% |\n",
            "| Epoch  91, train_time=713.4ms, eval_time=615.4ms |                         Train: loss=0.211, acc= 95.0% |\n",
            "| Epoch  96, train_time=741.5ms, eval_time=598.1ms |                         Train: loss=0.208, acc= 95.1% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.368, acc= 89.3% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.237, acc= 93.9% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=0.206, acc= 95.1% <<<\n",
            "****************************************************************************************************\n",
            "Task  3 (pmnist-3)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=962.5ms, eval_time=783.5ms |                         Train: loss=1.044, acc= 68.3% |\n",
            "| Epoch   6, train_time=976.5ms, eval_time=812.5ms |                         Train: loss=0.474, acc= 87.5% |\n",
            "| Epoch  11, train_time=900.4ms, eval_time=752.7ms |                         Train: loss=0.391, acc= 90.0% |\n",
            "| Epoch  16, train_time=892.7ms, eval_time=780.1ms |                         Train: loss=0.350, acc= 91.2% |\n",
            "| Epoch  21, train_time=911.6ms, eval_time=717.1ms |                         Train: loss=0.325, acc= 91.9% |\n",
            "| Epoch  26, train_time=900.9ms, eval_time=753.2ms |                         Train: loss=0.307, acc= 92.6% |\n",
            "| Epoch  31, train_time=913.6ms, eval_time=762.7ms |                         Train: loss=0.294, acc= 92.9% |\n",
            "| Epoch  36, train_time=891.1ms, eval_time=725.5ms |                         Train: loss=0.283, acc= 93.3% |\n",
            "| Epoch  41, train_time=922.8ms, eval_time=709.8ms |                         Train: loss=0.274, acc= 93.7% |\n",
            "| Epoch  46, train_time=1223.1ms, eval_time=843.5ms |                         Train: loss=0.267, acc= 94.0% |\n",
            "| Epoch  51, train_time=913.3ms, eval_time=868.4ms |                         Train: loss=0.261, acc= 94.2% |\n",
            "| Epoch  56, train_time=1032.0ms, eval_time=857.3ms |                         Train: loss=0.256, acc= 94.4% |\n",
            "| Epoch  61, train_time=896.2ms, eval_time=784.6ms |                         Train: loss=0.251, acc= 94.6% |\n",
            "| Epoch  66, train_time=895.1ms, eval_time=753.3ms |                         Train: loss=0.247, acc= 94.7% |\n",
            "| Epoch  71, train_time=1113.7ms, eval_time=714.8ms |                         Train: loss=0.243, acc= 94.9% |\n",
            "| Epoch  76, train_time=941.9ms, eval_time=757.9ms |                         Train: loss=0.240, acc= 95.1% |\n",
            "| Epoch  81, train_time=875.4ms, eval_time=707.7ms |                         Train: loss=0.237, acc= 95.2% |\n",
            "| Epoch  86, train_time=910.5ms, eval_time=775.2ms |                         Train: loss=0.235, acc= 95.3% |\n",
            "| Epoch  91, train_time=892.7ms, eval_time=909.4ms |                         Train: loss=0.232, acc= 95.5% |\n",
            "| Epoch  96, train_time=960.0ms, eval_time=713.2ms |                         Train: loss=0.230, acc= 95.6% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.480, acc= 86.8% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.289, acc= 92.9% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=0.316, acc= 92.3% <<<\n",
            ">>> Test on task  3 - pmnist-3       : loss=0.235, acc= 95.4% <<<\n",
            "****************************************************************************************************\n",
            "Task  4 (pmnist-4)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=1119.7ms, eval_time=922.8ms |                         Train: loss=0.913, acc= 74.2% |\n",
            "| Epoch   6, train_time=1068.2ms, eval_time=889.8ms |                         Train: loss=0.477, acc= 88.5% |\n",
            "| Epoch  11, train_time=1147.5ms, eval_time=899.7ms |                         Train: loss=0.409, acc= 90.6% |\n",
            "| Epoch  16, train_time=1084.8ms, eval_time=917.3ms |                         Train: loss=0.374, acc= 91.7% |\n",
            "| Epoch  21, train_time=1369.7ms, eval_time=913.4ms |                         Train: loss=0.352, acc= 92.5% |\n",
            "| Epoch  26, train_time=1166.0ms, eval_time=932.2ms |                         Train: loss=0.336, acc= 93.0% |\n",
            "| Epoch  31, train_time=1210.8ms, eval_time=1058.2ms |                         Train: loss=0.324, acc= 93.5% |\n",
            "| Epoch  36, train_time=1074.3ms, eval_time=916.4ms |                         Train: loss=0.314, acc= 93.9% |\n",
            "| Epoch  41, train_time=1063.3ms, eval_time=971.7ms |                         Train: loss=0.307, acc= 94.2% |\n",
            "| Epoch  46, train_time=1120.8ms, eval_time=907.5ms |                         Train: loss=0.300, acc= 94.5% |\n",
            "| Epoch  51, train_time=1087.2ms, eval_time=901.8ms |                         Train: loss=0.295, acc= 94.7% |\n",
            "| Epoch  56, train_time=1072.0ms, eval_time=951.7ms |                         Train: loss=0.290, acc= 94.9% |\n",
            "| Epoch  61, train_time=1064.5ms, eval_time=970.3ms |                         Train: loss=0.286, acc= 95.0% |\n",
            "| Epoch  66, train_time=1156.7ms, eval_time=871.8ms |                         Train: loss=0.283, acc= 95.2% |\n",
            "| Epoch  71, train_time=1144.2ms, eval_time=900.7ms |                         Train: loss=0.280, acc= 95.4% |\n",
            "| Epoch  76, train_time=1370.1ms, eval_time=1030.7ms |                         Train: loss=0.277, acc= 95.5% |\n",
            "| Epoch  81, train_time=1110.7ms, eval_time=902.3ms |                         Train: loss=0.275, acc= 95.6% |\n",
            "| Epoch  86, train_time=1069.9ms, eval_time=890.8ms |                         Train: loss=0.273, acc= 95.7% |\n",
            "| Epoch  91, train_time=1095.2ms, eval_time=883.0ms |                         Train: loss=0.271, acc= 95.8% |\n",
            "| Epoch  96, train_time=1254.2ms, eval_time=869.3ms |                         Train: loss=0.270, acc= 95.9% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.632, acc= 82.0% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.331, acc= 92.2% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=0.452, acc= 88.4% <<<\n",
            ">>> Test on task  3 - pmnist-3       : loss=0.315, acc= 94.1% <<<\n",
            ">>> Test on task  4 - pmnist-4       : loss=0.274, acc= 95.7% <<<\n",
            "****************************************************************************************************\n",
            "Task  5 (pmnist-5)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=1269.9ms, eval_time=1056.2ms |                         Train: loss=0.960, acc= 72.8% |\n",
            "| Epoch   6, train_time=1267.8ms, eval_time=1291.6ms |                         Train: loss=0.520, acc= 88.5% |\n",
            "| Epoch  11, train_time=1250.4ms, eval_time=1338.3ms |                         Train: loss=0.449, acc= 90.8% |\n",
            "| Epoch  16, train_time=1367.6ms, eval_time=1046.8ms |                         Train: loss=0.414, acc= 92.0% |\n",
            "| Epoch  21, train_time=1505.5ms, eval_time=1113.2ms |                         Train: loss=0.392, acc= 92.7% |\n",
            "| Epoch  26, train_time=1403.3ms, eval_time=1030.8ms |                         Train: loss=0.376, acc= 93.3% |\n",
            "| Epoch  31, train_time=1471.9ms, eval_time=1049.7ms |                         Train: loss=0.365, acc= 93.7% |\n",
            "| Epoch  36, train_time=1256.9ms, eval_time=1042.6ms |                         Train: loss=0.355, acc= 94.1% |\n",
            "| Epoch  41, train_time=1245.6ms, eval_time=1077.9ms |                         Train: loss=0.348, acc= 94.4% |\n",
            "| Epoch  46, train_time=1290.5ms, eval_time=1102.4ms |                         Train: loss=0.342, acc= 94.6% |\n",
            "| Epoch  51, train_time=1285.8ms, eval_time=1110.2ms |                         Train: loss=0.337, acc= 94.9% |\n",
            "| Epoch  56, train_time=1275.9ms, eval_time=1131.1ms |                         Train: loss=0.333, acc= 95.1% |\n",
            "| Epoch  61, train_time=1288.5ms, eval_time=1073.0ms |                         Train: loss=0.330, acc= 95.3% |\n",
            "| Epoch  66, train_time=1281.4ms, eval_time=1093.6ms |                         Train: loss=0.327, acc= 95.4% |\n",
            "| Epoch  71, train_time=1276.5ms, eval_time=1081.8ms |                         Train: loss=0.325, acc= 95.6% |\n",
            "| Epoch  76, train_time=1269.0ms, eval_time=1114.5ms |                         Train: loss=0.323, acc= 95.7% |\n",
            "| Epoch  81, train_time=1558.5ms, eval_time=1313.3ms |                         Train: loss=0.321, acc= 95.9% |\n",
            "| Epoch  86, train_time=1381.7ms, eval_time=1247.0ms |                         Train: loss=0.319, acc= 96.0% |\n",
            "| Epoch  91, train_time=1264.0ms, eval_time=1050.0ms |                         Train: loss=0.318, acc= 96.1% |\n",
            "| Epoch  96, train_time=1319.7ms, eval_time=1081.4ms |                         Train: loss=0.317, acc= 96.2% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.736, acc= 79.4% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.354, acc= 91.9% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=0.410, acc= 91.1% <<<\n",
            ">>> Test on task  3 - pmnist-3       : loss=0.363, acc= 94.0% <<<\n",
            ">>> Test on task  4 - pmnist-4       : loss=0.329, acc= 95.5% <<<\n",
            ">>> Test on task  5 - pmnist-5       : loss=0.324, acc= 96.0% <<<\n",
            "****************************************************************************************************\n",
            "Task  6 (pmnist-6)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=1442.0ms, eval_time=1266.7ms |                         Train: loss=0.978, acc= 73.6% |\n",
            "| Epoch   6, train_time=1462.4ms, eval_time=1414.7ms |                         Train: loss=0.563, acc= 88.9% |\n",
            "| Epoch  11, train_time=1590.0ms, eval_time=1220.1ms |                         Train: loss=0.494, acc= 91.1% |\n",
            "| Epoch  16, train_time=1708.4ms, eval_time=1363.2ms |                         Train: loss=0.461, acc= 92.2% |\n",
            "| Epoch  21, train_time=1405.9ms, eval_time=1275.1ms |                         Train: loss=0.439, acc= 92.9% |\n",
            "| Epoch  26, train_time=1595.8ms, eval_time=1262.7ms |                         Train: loss=0.425, acc= 93.4% |\n",
            "| Epoch  31, train_time=1425.4ms, eval_time=1448.2ms |                         Train: loss=0.414, acc= 93.9% |\n",
            "| Epoch  36, train_time=1598.2ms, eval_time=1211.4ms |                         Train: loss=0.406, acc= 94.3% |\n",
            "| Epoch  41, train_time=1434.0ms, eval_time=1227.2ms |                         Train: loss=0.399, acc= 94.6% |\n",
            "| Epoch  46, train_time=1418.3ms, eval_time=1312.0ms |                         Train: loss=0.393, acc= 94.8% |\n",
            "| Epoch  51, train_time=1429.9ms, eval_time=1209.6ms |                         Train: loss=0.389, acc= 95.0% |\n",
            "| Epoch  56, train_time=1663.6ms, eval_time=1197.8ms |                         Train: loss=0.385, acc= 95.3% |\n",
            "| Epoch  61, train_time=1424.9ms, eval_time=1478.7ms |                         Train: loss=0.382, acc= 95.4% |\n",
            "| Epoch  66, train_time=1443.1ms, eval_time=1364.7ms |                         Train: loss=0.380, acc= 95.6% |\n",
            "| Epoch  71, train_time=1408.0ms, eval_time=1208.7ms |                         Train: loss=0.377, acc= 95.7% |\n",
            "| Epoch  76, train_time=1373.0ms, eval_time=1231.7ms |                         Train: loss=0.376, acc= 95.9% |\n",
            "| Epoch  81, train_time=1487.1ms, eval_time=1201.2ms |                         Train: loss=0.374, acc= 96.0% |\n",
            "| Epoch  86, train_time=1678.7ms, eval_time=1246.1ms |                         Train: loss=0.373, acc= 96.1% |\n",
            "| Epoch  91, train_time=1472.8ms, eval_time=1218.5ms |                         Train: loss=0.372, acc= 96.2% |\n",
            "| Epoch  96, train_time=1828.7ms, eval_time=1226.6ms |                         Train: loss=0.371, acc= 96.3% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.713, acc= 80.5% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.450, acc= 89.5% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=0.445, acc= 91.0% <<<\n",
            ">>> Test on task  3 - pmnist-3       : loss=0.409, acc= 93.3% <<<\n",
            ">>> Test on task  4 - pmnist-4       : loss=0.395, acc= 94.3% <<<\n",
            ">>> Test on task  5 - pmnist-5       : loss=0.399, acc= 94.8% <<<\n",
            ">>> Test on task  6 - pmnist-6       : loss=0.379, acc= 96.0% <<<\n",
            "****************************************************************************************************\n",
            "Task  7 (pmnist-7)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=1832.3ms, eval_time=1559.7ms |                         Train: loss=1.004, acc= 75.6% |\n",
            "| Epoch   6, train_time=1997.6ms, eval_time=1664.3ms |                         Train: loss=0.606, acc= 89.5% |\n",
            "| Epoch  11, train_time=1587.0ms, eval_time=1396.6ms |                         Train: loss=0.544, acc= 91.5% |\n",
            "| Epoch  16, train_time=1622.1ms, eval_time=1375.7ms |                         Train: loss=0.513, acc= 92.6% |\n",
            "| Epoch  21, train_time=1588.4ms, eval_time=1397.7ms |                         Train: loss=0.493, acc= 93.2% |\n",
            "| Epoch  26, train_time=1557.7ms, eval_time=1414.8ms |                         Train: loss=0.480, acc= 93.7% |\n",
            "| Epoch  31, train_time=1588.1ms, eval_time=1403.5ms |                         Train: loss=0.471, acc= 94.1% |\n",
            "| Epoch  36, train_time=1687.3ms, eval_time=1667.1ms |                         Train: loss=0.463, acc= 94.5% |\n",
            "| Epoch  41, train_time=1623.4ms, eval_time=1624.5ms |                         Train: loss=0.457, acc= 94.8% |\n",
            "| Epoch  46, train_time=1873.5ms, eval_time=1660.8ms |                         Train: loss=0.453, acc= 95.0% |\n",
            "| Epoch  51, train_time=1632.9ms, eval_time=1669.9ms |                         Train: loss=0.449, acc= 95.3% |\n",
            "| Epoch  56, train_time=1631.2ms, eval_time=1394.9ms |                         Train: loss=0.446, acc= 95.5% |\n",
            "| Epoch  61, train_time=1619.4ms, eval_time=1462.6ms |                         Train: loss=0.444, acc= 95.6% |\n",
            "| Epoch  66, train_time=1603.5ms, eval_time=1532.4ms |                         Train: loss=0.442, acc= 95.8% |\n",
            "| Epoch  71, train_time=1598.1ms, eval_time=1517.6ms |                         Train: loss=0.440, acc= 95.9% |\n",
            "| Epoch  76, train_time=1685.9ms, eval_time=1556.3ms |                         Train: loss=0.439, acc= 96.0% |\n",
            "| Epoch  81, train_time=1686.6ms, eval_time=1621.2ms |                         Train: loss=0.438, acc= 96.1% |\n",
            "| Epoch  86, train_time=1597.1ms, eval_time=1426.5ms |                         Train: loss=0.438, acc= 96.2% |\n",
            "| Epoch  91, train_time=1711.5ms, eval_time=1427.4ms |                         Train: loss=0.437, acc= 96.3% |\n",
            "| Epoch  96, train_time=1594.6ms, eval_time=1421.0ms |                         Train: loss=0.437, acc= 96.4% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.786, acc= 78.9% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.652, acc= 84.6% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=0.535, acc= 89.3% <<<\n",
            ">>> Test on task  3 - pmnist-3       : loss=0.524, acc= 90.8% <<<\n",
            ">>> Test on task  4 - pmnist-4       : loss=0.463, acc= 93.5% <<<\n",
            ">>> Test on task  5 - pmnist-5       : loss=0.477, acc= 94.0% <<<\n",
            ">>> Test on task  6 - pmnist-6       : loss=0.461, acc= 95.2% <<<\n",
            ">>> Test on task  7 - pmnist-7       : loss=0.447, acc= 96.0% <<<\n",
            "****************************************************************************************************\n",
            "Task  8 (pmnist-8)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=1836.4ms, eval_time=1608.7ms |                         Train: loss=1.108, acc= 74.0% |\n",
            "| Epoch   6, train_time=1848.5ms, eval_time=1756.2ms |                         Train: loss=0.680, acc= 89.4% |\n",
            "| Epoch  11, train_time=1765.3ms, eval_time=1564.0ms |                         Train: loss=0.614, acc= 91.6% |\n",
            "| Epoch  16, train_time=1765.0ms, eval_time=1579.9ms |                         Train: loss=0.582, acc= 92.7% |\n",
            "| Epoch  21, train_time=1985.9ms, eval_time=1683.0ms |                         Train: loss=0.564, acc= 93.4% |\n",
            "| Epoch  26, train_time=1799.3ms, eval_time=1837.9ms |                         Train: loss=0.551, acc= 93.9% |\n",
            "| Epoch  31, train_time=2050.0ms, eval_time=1589.5ms |                         Train: loss=0.541, acc= 94.3% |\n",
            "| Epoch  36, train_time=2087.7ms, eval_time=1573.4ms |                         Train: loss=0.534, acc= 94.7% |\n",
            "| Epoch  41, train_time=1788.5ms, eval_time=1636.2ms |                         Train: loss=0.529, acc= 95.0% |\n",
            "| Epoch  46, train_time=1777.6ms, eval_time=1875.4ms |                         Train: loss=0.525, acc= 95.2% |\n",
            "| Epoch  51, train_time=1882.1ms, eval_time=1636.8ms |                         Train: loss=0.522, acc= 95.4% |\n",
            "| Epoch  56, train_time=1765.9ms, eval_time=1837.9ms |                         Train: loss=0.519, acc= 95.6% |\n",
            "| Epoch  61, train_time=1898.7ms, eval_time=1601.6ms |                         Train: loss=0.517, acc= 95.8% |\n",
            "| Epoch  66, train_time=1863.8ms, eval_time=1778.8ms |                         Train: loss=0.516, acc= 96.0% |\n",
            "| Epoch  71, train_time=1796.5ms, eval_time=1578.1ms |                         Train: loss=0.515, acc= 96.1% |\n",
            "| Epoch  76, train_time=1764.8ms, eval_time=1633.1ms |                         Train: loss=0.514, acc= 96.2% |\n",
            "| Epoch  81, train_time=1811.1ms, eval_time=1716.4ms |                         Train: loss=0.513, acc= 96.3% |\n",
            "| Epoch  86, train_time=1800.3ms, eval_time=1605.4ms |                         Train: loss=0.513, acc= 96.4% |\n",
            "| Epoch  91, train_time=1916.5ms, eval_time=1579.4ms |                         Train: loss=0.513, acc= 96.5% |\n",
            "| Epoch  96, train_time=1817.2ms, eval_time=1645.6ms |                         Train: loss=0.513, acc= 96.6% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=0.936, acc= 75.5% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.846, acc= 80.0% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=0.734, acc= 83.5% <<<\n",
            ">>> Test on task  3 - pmnist-3       : loss=0.740, acc= 85.8% <<<\n",
            ">>> Test on task  4 - pmnist-4       : loss=0.534, acc= 92.7% <<<\n",
            ">>> Test on task  5 - pmnist-5       : loss=0.562, acc= 93.1% <<<\n",
            ">>> Test on task  6 - pmnist-6       : loss=0.539, acc= 94.6% <<<\n",
            ">>> Test on task  7 - pmnist-7       : loss=0.536, acc= 95.4% <<<\n",
            ">>> Test on task  8 - pmnist-8       : loss=0.526, acc= 96.3% <<<\n",
            "****************************************************************************************************\n",
            "Task  9 (pmnist-9)\n",
            "****************************************************************************************************\n",
            "| Epoch   1, train_time=2005.1ms, eval_time=1987.5ms |                         Train: loss=1.071, acc= 77.9% |\n",
            "| Epoch   6, train_time=1923.6ms, eval_time=2028.5ms |                         Train: loss=0.735, acc= 90.0% |\n",
            "| Epoch  11, train_time=1925.9ms, eval_time=1749.7ms |                         Train: loss=0.677, acc= 92.0% |\n",
            "| Epoch  16, train_time=2168.0ms, eval_time=2055.1ms |                         Train: loss=0.648, acc= 93.0% |\n",
            "| Epoch  21, train_time=1949.4ms, eval_time=1733.6ms |                         Train: loss=0.630, acc= 93.7% |\n",
            "| Epoch  26, train_time=1962.0ms, eval_time=1875.4ms |                         Train: loss=0.619, acc= 94.1% |\n",
            "| Epoch  31, train_time=2236.7ms, eval_time=1799.3ms |                         Train: loss=0.610, acc= 94.5% |\n",
            "| Epoch  36, train_time=1922.7ms, eval_time=1780.6ms |                         Train: loss=0.604, acc= 94.9% |\n",
            "| Epoch  41, train_time=1987.1ms, eval_time=2256.8ms |                         Train: loss=0.599, acc= 95.2% |\n",
            "| Epoch  46, train_time=2155.4ms, eval_time=1794.8ms |                         Train: loss=0.596, acc= 95.4% |\n",
            "| Epoch  51, train_time=2329.5ms, eval_time=1810.7ms |                         Train: loss=0.593, acc= 95.6% |\n",
            "| Epoch  56, train_time=1944.5ms, eval_time=1775.1ms |                         Train: loss=0.591, acc= 95.7% |\n",
            "| Epoch  61, train_time=2039.3ms, eval_time=1877.6ms |                         Train: loss=0.590, acc= 95.9% |\n",
            "| Epoch  66, train_time=1988.7ms, eval_time=1902.7ms |                         Train: loss=0.589, acc= 96.0% |\n",
            "| Epoch  71, train_time=2248.9ms, eval_time=1735.7ms |                         Train: loss=0.588, acc= 96.2% |\n",
            "| Epoch  76, train_time=2062.7ms, eval_time=1797.8ms |                         Train: loss=0.587, acc= 96.3% |\n",
            "| Epoch  81, train_time=1988.2ms, eval_time=1833.8ms |                         Train: loss=0.587, acc= 96.4% |\n",
            "| Epoch  86, train_time=2203.0ms, eval_time=1937.2ms |                         Train: loss=0.587, acc= 96.5% |\n",
            "| Epoch  91, train_time=2098.1ms, eval_time=1980.4ms |                         Train: loss=0.588, acc= 96.6% |\n",
            "| Epoch  96, train_time=1966.8ms, eval_time=1832.6ms |                         Train: loss=0.588, acc= 96.7% |\n",
            "Calculating Fisher Information Matrix ...\n",
            "Calculated Fisher Information Matrix.\n",
            "----------------------------------------------------------------------------------------------------\n",
            ">>> Test on task  0 - pmnist-0       : loss=1.116, acc= 70.8% <<<\n",
            ">>> Test on task  1 - pmnist-1       : loss=0.683, acc= 84.1% <<<\n",
            ">>> Test on task  2 - pmnist-2       : loss=1.122, acc= 73.0% <<<\n",
            ">>> Test on task  3 - pmnist-3       : loss=0.883, acc= 82.0% <<<\n",
            ">>> Test on task  4 - pmnist-4       : loss=0.596, acc= 92.1% <<<\n",
            ">>> Test on task  5 - pmnist-5       : loss=0.651, acc= 91.7% <<<\n",
            ">>> Test on task  6 - pmnist-6       : loss=0.630, acc= 93.5% <<<\n",
            ">>> Test on task  7 - pmnist-7       : loss=0.627, acc= 94.4% <<<\n",
            ">>> Test on task  8 - pmnist-8       : loss=0.618, acc= 95.5% <<<\n",
            ">>> Test on task  9 - pmnist-9       : loss=0.600, acc= 96.3% <<<\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-c38a4637f877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-51-07fa1eab2269>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                                                                                       100 * acc[i,j]))\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mDone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracies ='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Done' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7nJmzhUnCvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}